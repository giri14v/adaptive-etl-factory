# services/codegen/main.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import Optional, Dict, Any
from pathlib import Path
import subprocess
import shutil
import json
import os
import textwrap
import datetime

app = FastAPI(title="CodeGen Agent")


class CodeGenRequest(BaseModel):
    # Either plan_path (string path on disk) OR plan (inline JSON) should be provided.
    plan_path: Optional[str] = None
    plan: Optional[Dict[str, Any]] = None
    output_path: str
    run_id: Optional[str] = None
    # optional: requestor can request cline usage; agent will still fall back if cline fails
    use_cline: Optional[bool] = False


@app.get("/health")
async def health():
    return {"status": "ok", "time": datetime.datetime.utcnow().isoformat() + "Z"}


def read_plan_from_path(plan_path: str) -> Dict[str, Any]:
    p = Path(plan_path)
    if not p.exists():
        raise FileNotFoundError(f"Plan file not found: {plan_path}")
    # Attempt to parse JSON
    data = json.loads(p.read_text(encoding="utf-8"))
    return data


def safe_write_text(path: str, content: str):
    p = Path(path)
    p.parent.mkdir(parents=True, exist_ok=True)
    p.write_text(content, encoding="utf-8")

def generate_fallback_script(plan: dict) -> str:
    return """#!/usr/bin/env python3
\"\"\"
Auto-generated ETL Script
Generated by CodeGen Agent

This script applies ETL operations inferred by the Planner
to a user-provided dataset (CSV / JSON / XLSX).
\"\"\"

import sys
import json
from pathlib import Path
import pandas as pd


def load_data(input_path: str) -> pd.DataFrame:
    path = Path(input_path)
    if not path.exists():
        raise FileNotFoundError(f"Input file not found: {input_path}")

    ext = path.suffix.lower()
    if ext == ".csv":
        return pd.read_csv(path)
    elif ext == ".json":
        return pd.read_json(path)
    elif ext == ".xlsx":
        return pd.read_excel(path)
    else:
        raise ValueError(f"Unsupported file format: {ext}")


def parse_date(df, columns, formats=None):
    formats = formats or []
    for col in columns:
        if col not in df.columns:
            continue
        for fmt in formats:
            try:
                parsed = pd.to_datetime(df[col], format=fmt, errors="coerce")
                if parsed.notna().any():
                    df[col] = parsed
                    break
            except Exception:
                pass
        df[col] = pd.to_datetime(df[col], errors="coerce")
    return df


def impute(df, columns, strategy="median"):
    for col in columns:
        if col not in df.columns:
            continue
        if strategy == "mean":
            df[col] = df[col].fillna(df[col].mean())
        elif strategy == "mode":
            mode = df[col].mode()
            if not mode.empty:
                df[col] = df[col].fillna(mode.iloc[0])
        else:
            df[col] = df[col].fillna(df[col].median())
    return df


def deduplicate(df, keys=None):
    if keys:
        valid_keys = [k for k in keys if k in df.columns]
        if valid_keys:
            return df.drop_duplicates(subset=valid_keys)
    return df.drop_duplicates()


def save_metrics(df, output_dir: Path):
    metrics = {
        "rows": int(len(df)),
        "columns": list(df.columns),
        "null_count": int(df.isna().sum().sum())
    }
    (output_dir / "metrics.json").write_text(
        json.dumps(metrics, indent=2),
        encoding="utf-8"
    )


def main(_, input_path, output_path):
    df = load_data(input_path)

    plan = {}
    try:
        plan = json.loads(Path(__file__).with_suffix(".plan.json").read_text())
    except Exception:
        pass

    steps = plan.get("steps", [])

    for step in steps:
        op = step.get("op")
        params = step.get("params") or {}

        if op == "parse_date":
            df = parse_date(df, step.get("columns", []), params.get("formats"))
        elif op == "impute":
            df = impute(df, step.get("columns", []), params.get("strategy", "median"))
        elif op == "deduplicate":
            df = deduplicate(df, params.get("keys"))

    out = Path(output_path)
    out.parent.mkdir(parents=True, exist_ok=True)
    df.to_csv(out, index=False)

    save_metrics(df, out.parent)
    print(f"ETL completed → {out}")


if __name__ == "__main__":
    _, input_path, output_path = sys.argv[1], sys.argv[2], sys.argv[3]
    main(None, input_path, output_path)
"""

@app.post("/codegen")
async def codegen(req: CodeGenRequest):
    """
    Behavior:
    1) Resolve plan (inline or from disk)
    2) Try to call `cline generate` if requested and available (best-effort)
    3) Otherwise, write fallback script to output_path
    4) Return JSON {status, output_path, stdout/stderr (if cline used)}
    """
    # Resolve plan
    plan = None
    try:
        if req.plan:
            plan = req.plan
        elif req.plan_path:
            plan = read_plan_from_path(req.plan_path)
        else:
            # empty plan → create minimal default plan so script still meaningful
            plan = {"steps": [{"id": "auto_parse_dates", "op": "parse_date", "columns": ["order_date"], "params": {"formats": ["%Y-%m-%d", "%d-%m-%Y"]}}]}
    except FileNotFoundError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Invalid plan: {e}")

    # Ensure output path parent exists and is writable
    out_path = Path(req.output_path)
    out_path.parent.mkdir(parents=True, exist_ok=True)

    # Try to call cline if user asked and cline exists
    cline_path = shutil.which("cline")
    if req.use_cline and cline_path:
        # write temporary plan file if plan provided inline
        tmp_plan = None
        try:
            if not req.plan_path:
                tmp_plan = out_path.parent / "temp_plan.json"
                tmp_plan.write_text(json.dumps(plan, indent=2), encoding="utf-8")
                plan_arg = str(tmp_plan)
            else:
                plan_arg = req.plan_path

            cmd = [cline_path, "generate", plan_arg, "python", "-o", str(out_path)]
            proc = subprocess.run(cmd, capture_output=True, text=True, timeout=120)
            stdout = proc.stdout
            stderr = proc.stderr
            if proc.returncode == 0:
                return {"status": "ok", "output_path": str(out_path), "mode": "cline", "stdout": stdout, "stderr": stderr}
            else:
                # fallthrough to fallback if cline failed (no credits, etc.)
                fallback_script = generate_fallback_script(plan)
                safe_write_text(str(out_path), fallback_script)
                return {"status": "ok", "output_path": str(out_path), "mode": "fallback_after_cline_failure", "stdout": stdout, "stderr": stderr}
        except subprocess.TimeoutExpired:
            # fallback
            fallback_script = generate_fallback_script(plan)
            safe_write_text(str(out_path), fallback_script)
            return {"status": "ok", "output_path": str(out_path), "mode": "fallback_cline_timeout"}
        except Exception as e:
            fallback_script = generate_fallback_script(plan)
            safe_write_text(str(out_path), fallback_script)
            return {"status": "ok", "output_path": str(out_path), "mode": "fallback_cline_exception", "error": str(e)}

    # Default fallback generation (deterministic)
    try:
        fallback_script = generate_fallback_script(plan)
        safe_write_text(str(out_path), fallback_script)
        # After safe_write_text(output_path, script)
        plan_path = Path(req.output_path).with_suffix(".plan.json")
        plan_path.write_text(json.dumps(plan, indent=2), encoding="utf-8")
        return {"status": "ok", "output_path": str(out_path), "mode": "fallback"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Code generation failed: {e}")
